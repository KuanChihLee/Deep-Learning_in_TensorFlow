# -*- coding: utf-8 -*-
"""ST: DL Python script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n2XWWrwkHhN0cIxJPKwyjChJ4fsMSFTr
"""

import os
import sys
import cv2
import numpy as np
import tensorflow as tf
from keras.preprocessing import image

def train(dropout=0.2, epochs=10, batch_size=8, valid_split=0.0, valid_data=None):
  ''' Using tf.keras module to train a 2-hidden layers model.
      - The first layer is a dense layers with 256 nodes with ReLU, batch normalization
        and dropout.
      - The second layer is a dense layers with 256 nodes with ReLU, batch normalization
        and dropout.
      - The output layer is 10 labels output with softmax.
      - The optimizer: Adam
      - Loss function: Sparse categorical crossentropy '''
  
  model = tf.keras.Sequential()
  model.add(tf.keras.layers.Flatten(input_shape=(32, 32, 3)))

  model.add(tf.keras.layers.Dense(256, bias_initializer="random_normal"))
  model.add(tf.keras.layers.BatchNormalization())
  model.add(tf.keras.layers.Activation('relu')) 
  tf.keras.layers.Dropout(dropout)
  model.add(tf.keras.layers.Dense(256, bias_initializer="random_normal"))
  model.add(tf.keras.layers.BatchNormalization())
  model.add(tf.keras.layers.Activation('relu')) 
  tf.keras.layers.Dropout(dropout)

  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))

  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=valid_data)
  return model
  
def load_model():
  ''' Loading an existed model through tf.keras module '''
  
  try:
    print("Loading model from 'model' !!")
    new_model = tf.keras.models.load_model('./model/model.ckpt')
    #new_model.summary()
  except:
    print("Can't load Model !!")
    print("End Program !!")
    sys.exit()
  return new_model

def load_cifar10():
  ''' Loading Cifar10 dataset through tf.keras module '''

  try:
    print("Loading Cifar10 !!")
    cifar10 = tf.keras.datasets.cifar10
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
  except:
    print("Can't load Cifar10 !!")
    print("End Program !!")
    sys.exit()
  return (x_train, y_train), (x_test, y_test) 


label_list = {0:"airplane", 1:"automobile", 2:"bird", 3:"cat", 
              4:"deer", 5:"dog", 6:"frog", 7:"horse", 8:"ship", 9:"truck"}
GPU_RUN = True
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  GPU_RUN = False
  print('GPU device not found. Using CPU !!')
else:
  print('Found GPU at: {}'.format(device_name))


if sys.argv[1] == "train":
  (x_train, y_train), (x_test, y_test) = load_cifar10()
  if GPU_RUN:
    with tf.device('/gpu:0'):
      model = train(dropout=0.4, epochs=10, batch_size=16, valid_data=(x_test, y_test))
  else:
      model = train(dropout=0.4, epochs=10, batch_size=16, valid_data=(x_test, y_test))
  print("Model saved in file: ./model/model.ckpt")
  file_path = "./model/"
  directory = os.path.dirname(file_path)
  if not os.path.exists(directory):
    os.makedirs(directory)
  model.save('./model/model.ckpt')
  
elif sys.argv[1] == "predict" or sys.argv[1] == "test":
  new_model = load_model()
  if GPU_RUN: 
    with tf.device('/gpu:0'):
      test = image.load_img(sys.argv[2], target_size=(32, 32, 3))
      prediction_vec = new_model.predict(np.reshape(test, (1, 32, 32, 3)))
      print(label_list[np.argmax(prediction_vec)])
  else:
      test = image.load_img(sys.argv[2], target_size=(32, 32, 3))
      prediction_vec = new_model.predict(np.reshape(test, (1, 32, 32, 3)))
      print(label_list[np.argmax(prediction_vec)])
      
elif sys.argv[1] == "eval":
  (x_train, y_train), (x_test, y_test) = load_cifar10()
  new_model = load_model()
  new_model.evaluate(x_test, y_test)
  
else:
  print("Wrong argument !! Please try 'train' or 'test' as an argument")